{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOKe98JX6Z1OUTTBL/eyCFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/INFO4080/blob/main/Week_10-Results_II/Week_10_In_Class_Activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 10: In-Class Activity\n",
        "\n",
        "Your Name"
      ],
      "metadata": {
        "id": "ghkm4G_Kan4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started\n",
        "\n",
        "* Colab - get notebook from gitmystuff DTSC4080 repository\n",
        "* Save a Copy in Drive\n",
        "* Remove Copy of\n",
        "* Edit your name\n",
        "* Attendance\n",
        "* Clean up Colab Notebooks folder\n",
        "* Submit shared link"
      ],
      "metadata": {
        "id": "NNUOZnWEaqKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Public Data\n",
        "\n",
        "* https://data.census.gov/\n",
        "* https://healthdata.gov/\n",
        "* Edgar: https://www.sec.gov/edgar\n",
        "* Bureau of Justice: https://bjs.ojp.gov/\n",
        "* IRS: https://www.irs.gov/statistics\n",
        "* Bureau of Economic Analysis: https://www.bea.gov/\n",
        "* Federal Reserve: https://www.federalreserve.gov/data.htm\n",
        "* DOE Data and Research: https://www2.ed.gov/rschstat/landing.jhtml?src=ft\n",
        "* Bureau of Labor Statistics: https://www.bls.gov/\n",
        "* US Patent and Trademark Office: https://www.uspto.gov/\n",
        "* National Centers for Environmental Information: https://www.ncei.noaa.gov/\n",
        "* World Bank: https://data.worldbank.org/\n",
        "* CIA World Factbook: https://www.cia.gov/the-world-factbook/\n",
        "* United Nations: https://data.un.org/\n",
        "* UNICEF: https://data.unicef.org/\n",
        "* Statistics Canada: https://www.statcan.gc.ca/\n",
        "* Eurostat: https://ec.europa.eu/eurostat\n",
        "* Organization for Economic Cooperation and Development: https://data.oecd.org/\n",
        "* UK National Health Service NHS Digital: https://digital.nhs.uk/\n",
        "* Google Finance: https://www.google.com/finance/\n",
        "* Google Trends: https://trends.google.com/trends/\n",
        "* Google Public Data Explorer: https://www.google.com/publicdata/directory\n",
        "* Amazon Web Services Public Data: https://registry.opendata.aws/\n",
        "* Data.gov: https://data.gov/\n",
        "* Google Ngram Viewer: https://books.google.com/ngrams/\n",
        "* The Corpus of Contemporary American English: https://www.english-corpora.org/coca/\n",
        "* University of California, Irvine, Center for Machine Learning: https://archive.ics.uci.edu/\n",
        "* Pew Research Center: https://www.pewresearch.org/\n",
        "* https://www.linkedin.com/learning/learning-public-data-sets-2/bureau-of-labor-statistics?resume=false&u=74650474\n",
        "\n"
      ],
      "metadata": {
        "id": "3bNQM76dx1AI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BigQuery\n",
        "\n",
        "* https://console.cloud.google.com/marketplace/product/google/bigquery.googleapis.com?_ga=2.211298837.1868925152.1707340152-1299486709.1704991752&project=studynotes-prod&returnUrl=%2Fbigquery%3F_ga%3D2.211298837.1868925152.1707340152-1299486709.1704991752%26project%3Dstudynotes-prod\n",
        "\n",
        "<pre>\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  `bigquery-public-data.usa_names.usa_1910_current`\n",
        "LIMIT 100\n",
        "</pre>\n",
        "\n",
        "<pre>\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  `bigquery-public-data.usa_names.usa_1910_current`\n",
        "WHERE\n",
        "  state = 'TX'\n",
        "LIMIT 100\n",
        "</pre>\n",
        "\n",
        "<pre>\n",
        "SELECT\n",
        "  MIN(year), MAX(year)\n",
        "FROM\n",
        "  `bigquery-public-data.usa_names.usa_1910_current`\n",
        "</pre>\n",
        "\n",
        "<pre>\n",
        "SELECT\n",
        "  name, COUNT(name) as cnt\n",
        "FROM\n",
        "  `bigquery-public-data.usa_names.usa_1910_current`\n",
        "GROUP BY name\n",
        "ORDER BY cnt DESC\n",
        "LIMIT 1\n",
        "</pre>\n",
        "\n",
        "<pre>\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  `bigquery-public-data.usa_names.usa_1910_current`\n",
        "WHERE\n",
        "  state = 'TX'\n",
        "AND\n",
        "  year = 2020\n",
        "LIMIT 100\n",
        "</pre>\n",
        "\n"
      ],
      "metadata": {
        "id": "wVhHy57pd1-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Public datasets\n",
        "\n",
        "* Add\n",
        "* Search for public datasets\n",
        "* Search of World Bank\n",
        "\n",
        "World Bank\n",
        "* https://databank.worldbank.org/metadataglossary/jobs/series/SI.POV.GINI"
      ],
      "metadata": {
        "id": "U61OtIl3VLsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "\n",
        "SELECT acs.geo_id, acs.total_pop, fips.state_name\n",
        "FROM\n",
        "`bigquery-public-data.census_bureau_acs.state_2010_1yr` as acs,\n",
        "`bigquery-public-data.census_utility.fips_codes_states` as fips\n",
        "WHERE acs.geo_id = fips.state_fips_code\n",
        "AND fips.state_name = 'Texas'\n",
        "\n",
        "</pre>\n",
        "\n",
        "<pre>\n",
        "SELECT *\n",
        "FROM `bigquery-public-data.census_bureau_acs.state_2010_1yr` as acs\n",
        "INNER JOIN  `bigquery-public-data.census_utility.fips_codes_states` as fips\n",
        "ON acs.geo_id = fips.state_fips_code\n",
        "</pre>"
      ],
      "metadata": {
        "id": "k7WC8zTRg-Mr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Research Paper Method Section\n",
        "\n",
        "From Gemini\n",
        "\n",
        "**Prompt**: I am writing a research paper and want to know what elements go in the method section\n",
        "\n",
        "**Response**:\n",
        "\n",
        "**Method**\n",
        "\n",
        "The method section of your research paper is crucial, as it details how you conducted your research and allows readers to assess its validity and replicability. Here are the key elements you should include:\n",
        "\n",
        "**1. Research Design:**\n",
        "\n",
        "* https://library.cityu.edu/researchguides/researchmethods/litreview\n",
        "* Briefly explain the type of research design you employed (e.g., experiment, survey, case study).\n",
        "* Justify your choice of design and how it aligns with your research question and objectives.\n",
        "\n",
        "**2. Participants or Subjects:**\n",
        "\n",
        "* Describe the characteristics of your participants or subjects, including demographics, selection criteria, and sample size.\n",
        "* Explain how you recruited participants and ensure ethical considerations were addressed (e.g., informed consent).\n",
        "\n",
        "**3. Materials and Equipment:**\n",
        "\n",
        "* List all the materials and equipment used in your research, including specific details like brand names, models, and software versions.\n",
        "* Describe any specific procedures or preparations undertaken for the materials or equipment.\n",
        "\n",
        "**4. Procedure:**\n",
        "\n",
        "* Provide a step-by-step explanation of how you conducted your research, ensuring clarity and conciseness.\n",
        "* Include details on data collection methods (e.g., surveys, interviews, observations) and any manipulations or interventions involved.\n",
        "*  If applicable, describe the order of events and any control measures implemented.\n",
        "\n",
        "**5. Data Analysis:**\n",
        "\n",
        "* Explain how you analyzed your data, including the specific statistical tests or qualitative analysis methods used.\n",
        "* Briefly justify your choice of analysis methods and their appropriateness for your research question and data type.\n",
        "\n",
        "**Additional Considerations:**\n",
        "\n",
        "* **Ethical Approval:** If your research involved human subjects or animals, mention the ethical approval process and the body that granted approval.\n",
        "* **Data Management:** Briefly describe how you stored and managed your data throughout the research process.\n",
        "* **Clarity and Conciseness:** Use clear and concise language, avoiding jargon and unnecessary details.\n",
        "* **Logical Organization:**  Structure the section logically, often using subheadings to present information in a clear and organized manner.\n",
        "\n",
        "Remember, the specific elements and level of detail required in your methods section may vary depending on your field of study and specific research question. It's always recommended to consult your research style guide or professor for specific formatting and content requirements."
      ],
      "metadata": {
        "id": "7NZ4_SknF-fX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results Section\n",
        "\n",
        "The results section of a research paper is all about presenting the cold, hard facts unearthed by your research. It acts like a bridge between the methodology you used and what you ultimately discovered. Here are the key points to remember:\n",
        "\n",
        "* **Focus on Findings:** It presents what you found, sticking to data and observations without interpretation or analysis. Think of it as laying out the evidence.\n",
        "* **Answer the Question:** The findings should directly address the research question(s) you posed at the outset of the paper.\n",
        "* **Logical Flow:** Organize your findings in a clear and logical sequence, often mirroring the structure of your methodology.\n",
        "* **Data Presentation:** Use tables, figures, and charts to effectively showcase your findings. Text descriptions should complement these visuals.\n",
        "* **Neutral Tone:** Avoid any bias or personal opinions in this section. Maintain a strictly objective and factual approach.\n",
        "* **Context is Key:** Briefly introduce the results section by reminding the reader of the research problem and the purpose of your study.\n",
        "* **Only Relevant Findings:** Include data directly connected to your research goals. Avoid cluttering the section with unnecessary details.\n",
        "\n",
        "Remember, the results section sets the stage for the discussion section, where you'll delve deeper into interpreting the meaning of your findings.\n",
        "\n",
        "The results section of a research paper is one of the most important parts, and it should only include the findings of the study. The results section should include:\n",
        "\n",
        "* Data: Data presented in tables, charts, graphs, and other figures\n",
        "* Contextual analysis: A sentence-based explanation of the meaning of the data\n",
        "* Secondary findings: Secondary outcomes, subgroup analyses, and more\n",
        "* Connection to research questions: How the data relates to the research questions\n",
        "\n",
        "The results section should not attempt to interpret or analyze the findings, only state the facts. The data may be placed into the text or on separate pages at the end of the manuscript.\n",
        "\n",
        "The results (or findings) section is one of the most important parts of a research paper, in which an author reports the findings of their study in connection to their research question(s). The results section should not attempt to interpret or analyze the findings, only state the facts.\n",
        "\n",
        "The Results section should include the findings of your study and ONLY the findings of your study. The findings include: Data presented in tables, charts, graphs, and other figures (may be placed into the text or on separate pages at the end of the manuscript) A contextual analysis of this data explaining its meaning in sentence form. All data that corresponds to the central research question(s) All secondary findings (secondary outcomes, subgroup analyses, etc.)\n"
      ],
      "metadata": {
        "id": "7QXMnzR6kaqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Research Datasets Example\n",
        "\n",
        "* https://console.cloud.google.com/marketplace/browse?filter=solution-type:dataset&_ga=2.130334793.770505259.1711051101-842379299.1707340435\n",
        "\n",
        "I am writing a research paper titled To what extent and through what mechanisms does religion influence the formation and expression of ultra-nationalist ideologies and movements within Western civilization? I am looking for some datasets to support this.\n",
        "\n",
        "Finding a direct causal link between religion and ultra-nationalism is complex, and datasets will likely reflect correlations that need further analysis. Here are some resources to explore for your research paper:\n",
        "\n",
        "**Datasets:**\n",
        "\n",
        "* World Values Survey (WVS): [https://www.worldvaluessurvey.org/](https://www.worldvaluessurvey.org/)\n",
        "    * Conducts surveys in many countries, including measures of religious beliefs and national pride.\n",
        "* Varieties of Democracy (V-Dem) Project: [https://www.v-dem.net/data/the-v-dem-dataset/](https://www.v-dem.net/data/the-v-dem-dataset/)\n",
        "    * Dataset on democracy and political regimes, including measures of nationalism. Might require coding religious variables yourself.\n",
        "* Pew Research Center: [https://www.pewresearch.org/](https://www.pewresearch.org/)\n",
        "    * Conducts surveys on religion and public opinion, some including national identity.\n",
        "\n",
        "**Additional Resources:**\n",
        "\n",
        "* Religion and State Conflict Dataset (RASCOD): [https://history.dartmouth.edu/recent-publications](https://history.dartmouth.edu/recent-publications)\n",
        "    * Focuses on religious violence, but might offer insights into how religion interacts with nationalism.\n",
        "* The Geospatial Analysis of Religion and Society (GARS): [https://www.e-education.psu.edu/sites/default/files/ethics/mapping-muslim-neighbors-case.pdf](https://www.e-education.psu.edu/sites/default/files/ethics/mapping-muslim-neighbors-case.pdf)\n",
        "    * Provides spatial data on religion around the world.\n",
        "\n",
        "**Considerations:**\n",
        "\n",
        "* **Correlations vs. Causation:** Datasets will likely show correlations between religious beliefs and nationalist attitudes. You will need to analyze these correlations carefully to avoid causal misinterpretations.\n",
        "* **Control Variables:**  Consider factors like economic inequality, political history, and ethnic composition that might influence both religion and nationalism.\n",
        "* **Religious Diversity:** Explore how different religions or denominations might relate to ultra-nationalism.\n",
        "* **Historical Context:**  Nationalism and religious expression have evolved over time. Consider historical periods relevant to your research.\n",
        "\n",
        "**Remember:** Datasets are just one piece of the puzzle. Analyze them alongside qualitative research (case studies, historical analysis) to build a strong argument about the relationship between religion and ultra-nationalism.\n"
      ],
      "metadata": {
        "id": "NxdQRHt_6b0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terms Related to Research\n",
        "\n",
        "* https://docs.google.com/document/d/1a_lCcwkEhuolVEWumeGRRzBHnEQGgiTJmyjJuF3z3Pw/edit?usp=sharing"
      ],
      "metadata": {
        "id": "6yridgHAlUZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PowerPoint Project\n",
        "\n",
        "* https://docs.google.com/document/d/1onb_1KS8RCDc2McbCDp1IewIXg47uwi1URTgDZFcLQY/edit?usp=sharing"
      ],
      "metadata": {
        "id": "_8RA45bllgda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec\n",
        "\n",
        "https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469\n",
        "\n",
        "* Turning words into meaningful / similar numbers\n",
        "* Word embeddings\n",
        "* Neural Networks, Backpropagation, ArgMax, SoftMax, and Cross Entropy\n",
        "\n",
        "#### Word Embeddings\n",
        "\n",
        "Representations of words as numerical vectors that are based on their relationship to other words\n",
        "\n",
        "#### Neural Network\n",
        "\n",
        "A machine learning method that uses interconnected nodes or neurons to process data in a way that mimics the human brain\n",
        "\n",
        "#### Backpropagation\n",
        "\n",
        "Works by testing for errors from the weights of a neuron and then going back and fine tuning those weights, ex. gradient descent\n",
        "\n",
        "#### Argmax\n",
        "\n",
        "Returns the indices of the max value along an axis\n",
        "\n",
        "#### Softmax\n",
        "\n",
        "A vector of probabilities for each possible outcome such as classification\n",
        "\n",
        "#### Cross Entropy\n",
        "\n",
        "Measures the difference, entropy, between probabilities. Entropy is the number of bits required to transmit a randomly selected event from a probability distribution, a Monte Carlo method for importance sampling\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4nMmtr18uMxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similarity\n",
        "\n",
        "* A neural network can be userd to assign different values to the same word used in different contexts\n",
        "* Activation functions and associated weights are used for each value assigned to a word\n",
        "* Depneding on context a word with the largest weight will be chosen\n",
        "* Since a word has multiple values, a vector, it is possible to 'plot' the words thus providing a graphed similarity with other words"
      ],
      "metadata": {
        "id": "fpwEqlGGCsKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CBOW\n",
        "\n",
        "Uses context to predict a target word, a type of unsupervised learning, learning from unlabeled data"
      ],
      "metadata": {
        "id": "udipph2iJDre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Skip Gram\n",
        "\n",
        "Predicts context words given a target word"
      ],
      "metadata": {
        "id": "7TCFHM39JGtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Negative Sampling\n",
        "\n",
        "Aims to maximize the similarity of words in the same context and minimize when used in different contexts"
      ],
      "metadata": {
        "id": "byFqWoUqJY1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source = https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469 by Allison Parrish\n",
        "import urllib.request, json\n",
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/gitmystuff/Datasets/main/xkcd.json'\n",
        "with urllib.request.urlopen(url) as url:\n",
        "    color_data = json.load(url)\n",
        "\n",
        "type(color_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igklE6u7SoxM",
        "outputId": "3681454b-1870-4739-c86b-7ba95f8c9e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def hex_to_int(s):\n",
        "    s = s.lstrip(\"#\")\n",
        "    return int(s[:2], 16), int(s[2:4], 16), int(s[4:6], 16)\n",
        "\n",
        "def distance(coord1, coord2):\n",
        "    # note, this is VERY SLOW, don't use for actual code\n",
        "    return math.sqrt(sum([(i - j)**2 for i, j in zip(coord1, coord2)]))\n",
        "\n",
        "def subtractv(coord1, coord2):\n",
        "    return [c1 - c2 for c1, c2 in zip(coord1, coord2)]\n",
        "\n",
        "def addv(coord1, coord2):\n",
        "    return [c1 + c2 for c1, c2 in zip(coord1, coord2)]\n",
        "\n",
        "def meanv(coords):\n",
        "    # assumes every item in coords has same length as item 0\n",
        "    sumv = [0] * len(coords[0])\n",
        "    for item in coords:\n",
        "        for i in range(len(item)):\n",
        "            sumv[i] += item[i]\n",
        "    mean = [0] * len(sumv)\n",
        "    for i in range(len(sumv)):\n",
        "        mean[i] = float(sumv[i]) / len(coords)\n",
        "    return mean\n",
        "\n",
        "def closest(space, coord, n=5):\n",
        "    closest = []\n",
        "    for key in sorted(space.keys(),\n",
        "                        key=lambda x: distance(coord, space[x]))[:n]:\n",
        "        closest.append(key)\n",
        "    return closest"
      ],
      "metadata": {
        "id": "NHvu-VMqWQ2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = dict()\n",
        "for item in color_data['colors']:\n",
        "    colors[item[\"color\"]] = hex_to_int(item[\"hex\"])\n",
        "\n",
        "print('olive', colors['olive'])\n",
        "print('red', colors['red'])\n",
        "print('black', colors['black'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V74PwNXsVgu_",
        "outputId": "5a86e04d-1d8b-462f-8911-1a18c4211772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "olive (110, 117, 14)\n",
            "red (229, 0, 0)\n",
            "black (0, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest(colors, colors['red'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La7Dm7p5XCwa",
        "outputId": "2fd91c95-5169-4033-bdb5-d571e1592658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['red', 'fire engine red', 'bright red', 'tomato red', 'cherry red']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subtract colors\n",
        "closest(colors, subtractv(colors['purple'], colors['red']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRRNnKQUXSoD",
        "outputId": "6b80b92f-0747-4d76-c09e-f5699ba08329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['darker blue', 'cobalt blue', 'royal blue', 'darkish blue', 'true blue']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add colors\n",
        "closest(colors, addv(colors['blue'], colors['green']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_3U5u8mXaj-",
        "outputId": "28454460-f9d7-40bc-bd1c-d8a9272e1c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bright turquoise', 'bright light blue', 'bright aqua', 'cyan', 'neon blue']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the average of black and white: medium grey\n",
        "closest(colors, meanv([colors['black'], colors['white']]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WSSbBBNXm6O",
        "outputId": "860717c2-b2de-465c-8b33-ee04d213bf4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['medium grey', 'purple grey', 'steel grey', 'battleship grey', 'grey purple']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an analogy: pink is to red as X is to blue\n",
        "pink_to_red = subtractv(colors['pink'], colors['red'])\n",
        "closest(colors, addv(pink_to_red, colors['blue']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t69DbOY9XuIQ",
        "outputId": "2c6dcb1c-40df-41b0-f1c5-91b2113397ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neon blue', 'bright sky blue', 'bright light blue', 'cyan', 'bright cyan']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another example:\n",
        "navy_to_blue = subtractv(colors['navy'], colors['blue'])\n",
        "closest(colors, addv(navy_to_blue, colors['green']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdixP7OkXuvs",
        "outputId": "19f7ec55-6abf-44e0-97a0-f3eb5071dc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['darker green',\n",
              " 'true green',\n",
              " 'dark grass green',\n",
              " 'grassy green',\n",
              " 'racing green']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Overview\n",
        "\n",
        "(RNN, Seq2Seq, Attention, Transformers)\n",
        "\n",
        "* The attention mechanism allows the model to focus on different parts of the input text. This helps the model to generate more accurate predictions. This allows words in a text sequence to pay attention to the earlier words in the sequence. This helps to model large text sequences in a correct manner.\n",
        "* Transformers are big and slow but can be done in parallel, unlike RNNs\n",
        "* Provides longer range than LSTM\n",
        "* Created for RNNs (LSTMs), but transformers only use attention\n",
        "* Assign varying levels of importance to different parts of a sentence or text\n",
        "* Capture contextual information effectively\n",
        "* Understand the relationships between words\n",
        "* Extract the most relevant parts of a query while disregarding less important ones\n",
        "* Comprehend pronouns, two-sided words, and related sentences more effectively\n",
        "* Generate coherent answers for queries\n"
      ],
      "metadata": {
        "id": "7bR2tDdFurcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNNs\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Recurrent_neural_network\n",
        "* x in time t, is input to RNN unit, and outputs a hidden vector, or state, at time t\n",
        "\n",
        "#### Types of RNNs\n",
        "\n",
        "* https://www.educative.io/answers/what-are-the-types-of-rnn"
      ],
      "metadata": {
        "id": "9CAImaovwnxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM\n",
        "\n",
        "https://en.wikipedia.org/wiki/Long_short-term_memory\n",
        "\n",
        "* Cell\n",
        "* Input Gate\n",
        "* Output Gate\n",
        "* Forget Gate\n",
        "* Activation Function (represented by $\\sigma$)\n",
        "* https://www.researchgate.net/figure/Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell_fig5_329362532\n",
        "* The cell state represents the memory of the network, information over time, while the hidden state contains the (new) processed information that is passed to the next time step"
      ],
      "metadata": {
        "id": "ekdR37dO1mGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq\n",
        "\n",
        "* Encoder / Decoder\n",
        "* https://en.wikipedia.org/wiki/Seq2seq\n",
        "* https://www.researchgate.net/figure/Seq2Seq-model-neural-encoder-and-decoder-32_fig4_334023532\n",
        "* h(t), a compressed representation (vector) of the input (thought vector), is between encoder and decoder\n",
        "* A problem with Seq2Seq is using long passages, long-term dependencies, and remembering context\n",
        "* h(t) always has the same size and can cause a bottle neck"
      ],
      "metadata": {
        "id": "scz3qFHKzJQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM vs Seq2Seq\n",
        "\n",
        "* Both are many to many models\n",
        "* LSTMs are building blocks\n",
        "* Seq2Seq is an architecture built from encoder LSTM and decoder LSTM, etc."
      ],
      "metadata": {
        "id": "KCm4aNrT3aOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### All You Need is Attention\n",
        "\n",
        "* For each output token, we want to know which input to pay attention to by using weights\n",
        "* https://theaisummer.com/attention/\n",
        "* Attention layer is a mapping of inputs to outputs\n",
        "\n",
        "#### No More RNN\n",
        "\n",
        "* RNNs are slow because they are sequential\n",
        "* Cannot be parallelized\n",
        "* Vanishing Gradients"
      ],
      "metadata": {
        "id": "m2baafJ837MH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer\n",
        "\n",
        "* Stack of attention layers\n",
        "* Pre trained stack of mappings from Encoder to Decoder\n",
        "* The attention function can be considered a mapping between a query and a set of key-value pairs to an output\n",
        "\n",
        "Sources\n",
        "\n",
        "* https://arxiv.org/abs/1706.03762\n",
        "* https://machinelearningmastery.com/the-transformer-attention-mechanism/"
      ],
      "metadata": {
        "id": "7szSXEqE8JOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLMs - Tokens and Transformers\n",
        "\n",
        "* Completion vs Chat\n",
        "* Chat needs context, memory\n",
        "* LangChain\n",
        "\n",
        "HuggingFace Transformers\n",
        "\n",
        "https://huggingface.co/models\n",
        "\n",
        "* Sentiment Analysis\n",
        "* Text Generation\n",
        "* Masked Language Modeling\n",
        "* NER\n",
        "* Summarization\n",
        "* Translation\n",
        "* Question and Answer\n",
        "* Zero-Shot Classification\n",
        "\n",
        "Source\n",
        "\n",
        "* https://deeplearningcourses.com/c/data-science-transformers-nlp"
      ],
      "metadata": {
        "id": "nlLlzOuj4XI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "SL2mun-HwPEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Analysis"
      ],
      "metadata": {
        "id": "FAFVOLD0oEfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Generation"
      ],
      "metadata": {
        "id": "P6yt0s9soMf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masked Language Modeling"
      ],
      "metadata": {
        "id": "A90bbvA0oSpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otN2cXd_os_E",
        "outputId": "02281c2f-8abc-493d-df5a-a2607599dca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-28 19:56:44--  https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 172.67.213.166, 104.21.23.210, 2606:4700:3030::ac43:d5a6, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|172.67.213.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5085081 (4.8M) [text/csv]\n",
            "Saving to: ‘bbc_text_cls.csv’\n",
            "\n",
            "bbc_text_cls.csv    100%[===================>]   4.85M  12.5MB/s    in 0.4s    \n",
            "\n",
            "2024-03-28 19:56:45 (12.5 MB/s) - ‘bbc_text_cls.csv’ saved [5085081/5085081]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER"
      ],
      "metadata": {
        "id": "u8P4XRfup4ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# conll 2003\n",
        "!wget -nc https://lazyprogrammer.me/course_files/nlp/ner_train.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaTLya-5p6XS",
        "outputId": "2d584b14-2d34-4b73-9a37-ea4cb5e28ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-28 20:02:00--  https://lazyprogrammer.me/course_files/nlp/ner_train.pkl\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 104.21.23.210, 172.67.213.166, 2606:4700:3030::ac43:d5a6, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|104.21.23.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4757208 (4.5M) [application/octet-stream]\n",
            "Saving to: ‘ner_train.pkl’\n",
            "\n",
            "ner_train.pkl       100%[===================>]   4.54M  7.33MB/s    in 0.6s    \n",
            "\n",
            "2024-03-28 20:02:01 (7.33 MB/s) - ‘ner_train.pkl’ saved [4757208/4757208]\n",
            "\n",
            "--2024-03-28 20:02:01--  https://lazyprogrammer.me/course_files/nlp/ner_test.pkl\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 104.21.23.210, 172.67.213.166, 2606:4700:3030::ac43:d5a6, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|104.21.23.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1201978 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘ner_test.pkl’\n",
            "\n",
            "ner_test.pkl        100%[===================>]   1.15M  3.48MB/s    in 0.3s    \n",
            "\n",
            "2024-03-28 20:02:02 (3.48 MB/s) - ‘ner_test.pkl’ saved [1201978/1201978]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarization"
      ],
      "metadata": {
        "id": "AFEzevPWrjfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import textwrap\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "3xCYFIiLrlvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translation"
      ],
      "metadata": {
        "id": "RBSr8E3tsWnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -nq spa-eng.zip\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXvnGU49sM9A",
        "outputId": "9103b339-9329-41d8-c72e-9312a472a33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-28 20:13:25--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.115.207, 172.253.122.207, 172.253.63.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.115.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "\rspa-eng.zip           0%[                    ]       0  --.-KB/s               \rspa-eng.zip         100%[===================>]   2.52M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-03-28 20:13:25 (218 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
            "\n",
            "bbc_text_cls.csv  ner_test.pkl\tner_train.pkl  sample_data  spa-eng  spa-eng.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question Answer"
      ],
      "metadata": {
        "id": "xJQNTlGcuC6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero Shot Classification"
      ],
      "metadata": {
        "id": "BlsmgdjOum8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import textwrap\n"
      ],
      "metadata": {
        "id": "jMbaeJubutnZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}